services:
  postgres:
    image: kartoza/postgis:16-3.4
    volumes:
      - openvista-data:/var/lib/postgresql
      - ./docker/sql-scripts:/docker-entrypoint-initdb.d
    environment:
      - POSTGRES_DB=${DB_NAME}
      - POSTGRES_USER=${DB_USERNAME}
      - POSTGRES_PASS=${DB_PASSWORD}
      - ALLOW_IP_RANGE=0.0.0.0/0
    ports:
      - "5555:5432"
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${DB_USERNAME}" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - app-network
  keycloak:
    image: quay.io/keycloak/keycloak
    command: start-dev
    environment:
      # KC_DB: postgres
      # KC_DB_URL_HOST: postgres
      # KC_DB_URL_DATABASE: ${DB_NAME}
      # KC_DB_SCHEMA: keycloak # <---- THIS IS THE KEY PART
      # KC_DB_USERNAME: ${DB_USERNAME}
      # KC_DB_PASSWORD: ${DB_PASSWORD}

      # Admin user (first-time)
      KEYCLOAK_ADMIN: ${KEYCLOAK_ADMIN_USER}
      KEYCLOAK_ADMIN_PASSWORD: ${KEYCLOAK_ADMIN_PASSWORD}

      # Development settings
      KC_HTTP_ENABLED: "true"
      KC_HOSTNAME_STRICT: "false"
      KC_LOG_LEVEL: INFO
    ports:
      - "8080:8080"
    volumes:
      - keycloak_data:/opt/keycloak/data
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - app-network
  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"   # S3 API
      - "9001:9001"   # MinIO Console UI
    environment:
      MINIO_ROOT_USER: ${AWS_ACCESS_KEY_ID}
      MINIO_ROOT_PASSWORD: ${AWS_SECRET_ACCESS_KEY}
    volumes:
      - minio_data:/data
    restart: always
    networks:
      - app-network
  # Optional: auto-create bucket "openvista"
  minio_mcbucket:
    image: minio/mc
    container_name: minio_mcbucket
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      sleep 5;
      mc alias set myminio http://minio:9000 admin minio123;
      mc mb -p myminio/openvista;
      exit 0;
      "
    networks:
      - app-network
  
  titiler:
    image: ghcr.io/developmentseed/titiler
    platform: linux/amd64
    restart: always
    command: >
      uvicorn titiler.application.main:app
      --host 0.0.0.0
      --port 8000
      --workers 1
    depends_on:
      - minio
    ports:
      - "8082:8000"
    environment:
      # Important: TiTiler uses boto3 under the hood â†’ same as AWS S3 config
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}

      # Tell TiTiler to talk to MinIO instead of AWS S3
      AWS_ENDPOINT_URL: http://minio:9000
      AWS_S3_ENDPOINT: http://minio:9000

      # Disable HTTPS requirement
      AWS_HTTPS: "NO"
      AWS_NO_SIGN_REQUEST: "NO"

      # Allow insecure requests (TiTiler uses requests)
      GDAL_DISABLE_READDIR_ON_OPEN: "EMPTY_DIR"
      VSI_CACHE: "TRUE"

      # TiTiler private-access setup
      TITILER_ALLOW_S3: "TRUE"        # enable S3-based access
      TITILER_S3_ENDPOINT: http://minio:9000
      TITILER_S3_REGION: ${S3_REGION}
      CPL_VSIL_SHOW_NETWORK_STATS: TRUE
      # This is important for MinIO
      AWS_REGION: ${S3_REGION}
      CPL_VSIL_CURL_USE_S3: "YES"

      AWS_VIRTUAL_HOSTING: "FALSE"

    # Allow TiTiler to resolve http://minio inside Docker network
    networks:
      - app-network
  
  redis:
    image: redis:latest
    restart: always
    networks:
      - app-network

  airflow-webserver:
    build: ./docker/airflow
    command: webserver
    entrypoint: [ "/usr/bin/dumb-init", "--", "/entrypoint" ]
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    shm_size: 2gb
    env_file :
     - .env
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${DB_USERNAME}:${DB_PASSWORD}@postgres/${DB_NAME}?options=-csearch_path%3Dairflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://${DB_USERNAME}:${DB_PASSWORD}@postgres/${DB_NAME}?options=-csearch_path%3Dairflow
      - AIRFLOW__CELERY__BROKER_URL=redis://:@redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__API__AUTH_BACKEND=airflow.api.auth.backend.basic_auth
      - _AIRFLOW_DB_UPGRADE=true
      - _AIRFLOW_WWW_USER_CREATE=true
      - _AIRFLOW_WWW_USER_USERNAME=${AIRFLOW_USER_USERNAME}
      - _AIRFLOW_WWW_USER_PASSWORD=${AIRFLOW_USER_PASSWORD}
      - AIRFLOW__WEBSERVER__SECRET_KEY="openvista-super-secret-key"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./static:/opt/airflow/static
      - ./docker/airflow/config:/opt/airflow/config
    ports:
      - "8081:8080"
    healthcheck:
      test: [ "CMD-SHELL", "[ -f /opt/airflow/airflow-webserver.pid ]" ]
      interval: 30s
      timeout: 30s
      retries: 3
    restart: always
    networks:
      - app-network

  airflow-scheduler:
    build: ./docker/airflow
    command: scheduler
    entrypoint: [ "/usr/bin/dumb-init", "--", "/entrypoint" ]
    depends_on:
      postgres:
        condition: service_healthy
      airflow-webserver:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    shm_size: 2gb
    env_file :
     - .env
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${DB_USERNAME}:${DB_PASSWORD}@postgres/${DB_NAME}?options=-csearch_path%3Dairflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://${DB_USERNAME}:${DB_PASSWORD}@postgres/${DB_NAME}?options=-csearch_path%3Dairflow
      - AIRFLOW__CELERY__BROKER_URL=redis://:@redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__WEBSERVER__SECRET_KEY="openvista-super-secret-key"
      - AIRFLOW__API__AUTH_BACKEND=airflow.api.auth.backend.basic_auth
    volumes:
      - ./dags:/opt/airflow/dags
      - ./static:/opt/airflow/static
      - ./docker/airflow/config:/opt/airflow/config
    restart: always
    networks:
      - app-network

  airflow-worker:
    build: ./docker/airflow
    command: celery worker
    mem_limit: 12g
    entrypoint: [ "/usr/bin/dumb-init", "--", "/entrypoint" ]
    depends_on:
      postgres:
        condition: service_healthy
      airflow-scheduler:
        condition: service_started
    # deploy:
    #   resources:
    #     limits:
    #       memory: 12G
    #     reservations:
    #       memory: 4G
    # shm_size: 12gb
    env_file :
     - .env
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${DB_USERNAME}:${DB_PASSWORD}@postgres/${DB_NAME}?options=-csearch_path%3Dairflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://${DB_USERNAME}:${DB_PASSWORD}@postgres/${DB_NAME}?options=-csearch_path%3Dairflow
      - AIRFLOW__CELERY__BROKER_URL=redis://:@redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__WEBSERVER__SECRET_KEY="openvista-super-secret-key"
      - AIRFLOW__API__AUTH_BACKEND=airflow.api.auth.backend.basic_auth
    volumes:
      - ./dags:/opt/airflow/dags
      - ./static:/opt/airflow/static
      - ./docker/airflow/config:/opt/airflow/config
    restart: always
    networks:
      - app-network

  airflow-init:
    build: ./docker/airflow
    entrypoint: /bin/bash
    command:
      - -c
      - |
        mkdir -p /sources/logs /sources/dags /sources/plugins
        chown -R "${AIRFLOW_UID}:0" /sources/{logs,dags,plugins}
        exec /entrypoint airflow version
    env_file :
     - .env
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${DB_USERNAME}:${DB_PASSWORD}@postgres/${DB_NAME}?options=-csearch_path%3Dairflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://${DB_USERNAME}:${DB_PASSWORD}@postgres/${DB_NAME}?options=-csearch_path%3Dairflow
      - AIRFLOW__CELERY__BROKER_URL=redis://:@redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - _AIRFLOW_DB_UPGRADE=true
      - _AIRFLOW_WWW_USER_CREATE=true
      - _AIRFLOW_WWW_USER_USERNAME=${AIRFLOW_USER_USERNAME}
      - _AIRFLOW_WWW_USER_PASSWORD=${AIRFLOW_USER_PASSWORD}
      - AIRFLOW__WEBSERVER__SECRET_KEY="openvista-super-secret-key"
    user: "0:0"
    volumes:
      - .:/sources
      - ./static:/opt/airflow/static
      - ./docker/airflow/config:/opt/airflow/config
    networks:
      - app-network

volumes:
  openvista-data:
  minio_data:
  keycloak_data:


networks:
  app-network:
